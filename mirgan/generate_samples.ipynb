{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from architecture import Generator\n",
    "from preprocessing_utils import detokenizer, calc_charmap\n",
    "from mirgan_utils import gpu_test, to_var, decode_onehot\n",
    "\n",
    "from generate_samples_args import process_argv, is_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opts= {'generator': '../tmp/test2/models/final-generator.pt', 'samples': 1000, 'output': '../output/example_gan.txt'}\n"
     ]
    }
   ],
   "source": [
    "if is_notebook():\n",
    "    generator = \"../tmp/test2/models/final-generator.pt\"\n",
    "    samples = 1000\n",
    "    output = \"../output/example_gan.txt\"\n",
    "\n",
    "    argv = ['filename.py',\n",
    "            \"--generator\", generator,\n",
    "            \"--samples\", samples,\n",
    "            \"--output\", output\n",
    "            ]\n",
    "    opts = process_argv(argv)\n",
    "\n",
    "if not is_notebook():\n",
    "    opts = process_argv(sys.argv)\n",
    "\n",
    "print(\"opts=\", opts)\n",
    "\n",
    "model_path = opts['generator']\n",
    "number_samples = int(opts['samples'])\n",
    "txt_output = opts['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_sequences_with_P = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_sample(batch_size):\n",
    "  z_input = to_var(torch.randn(batch_size, 100))\n",
    "  fake_samples = generator(z_input).detach()\n",
    "  return fake_samples\n",
    "\n",
    "def generate_sequences():\n",
    "  r = []\n",
    "  counter = 0\n",
    "  while counter < number_samples:\n",
    "    generated_samples = generator_sample(batch_size)\n",
    "    generated_samples_np = (generated_samples.data).cpu().numpy()\n",
    "\n",
    "    for seq in generated_samples_np:\n",
    "      seq = decode_onehot(seq)\n",
    "      seq = detokenizer(seq, inv_charmap)\n",
    "      seq = ''.join(seq).rstrip('P')\n",
    "\n",
    "      if remove_sequences_with_P and ('P' in seq):\n",
    "          continue\n",
    "\n",
    "      counter += 1\n",
    "      r.append(seq)\n",
    "  return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt(path, output):\n",
    "  if path is None: return\n",
    "  \n",
    "  with open(path, 'w') as txtfile:\n",
    "    for seq in output:\n",
    "      txtfile.write(seq + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, device(type='cuda'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda, device = gpu_test()\n",
    "print(f'use_cuda={use_cuda} device={device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "charmap, inv_charmap = calc_charmap('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (fc1): Linear(in_features=100, out_features=61952, bias=True)\n",
       "  (block): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (res_block): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (res_block): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (res_block): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (res_block): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (res_block): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv1d(512, 5, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charmap_len = 5\n",
    "\n",
    "max_side = 11\n",
    "max_length = max_side * max_side\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "hidden = 512\n",
    "\n",
    "generator = Generator( charmap_len, max_length, batch_size, hidden ).to(device=device)\n",
    "generator.load_state_dict(torch.load(model_path))\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_txt(txt_output, sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6070bf36e016a2c44bee296e1e25268245dd754c68fdedbd78ba329a2bfda587"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
