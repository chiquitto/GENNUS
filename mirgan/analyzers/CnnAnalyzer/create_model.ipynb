{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data config\n",
    "POS_FILE = \"../../../input/cnn_analyzer_mirtron.csv\"\n",
    "NEG_FILE = \"../../../input/cnn_analyzer_mirna.csv\"\n",
    "\n",
    "OUTPUT_DIR = './output/cnnanalyzer_models'\n",
    "\n",
    "# Preprocessing data config\n",
    "MAXLEN = 121\n",
    "PADNT = \"N\"\n",
    "POS_LABEL = 1\n",
    "NEG_LABEL = 0\n",
    "\n",
    "# Model config\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 512\n",
    "LR = 0.0001\n",
    "HIDDEN_LAYERS = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from structure.BinaryClassificator import BinaryClassificator\n",
    "from rna_dataset import RNADataset\n",
    "from cnnanalyzer_utils import gpu_test, save_models, eval_model, \\\n",
    "        read_input_csv, contains_certain_characters, generate_onehot_encoder, \\\n",
    "        tokenizer, onehot_tokenized, eval_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, device(type='cuda'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda, device = gpu_test()\n",
    "(use_cuda, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_runid():\n",
    "  return datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "  \n",
    "run_id = gen_runid()\n",
    "run_dir = f\"{OUTPUT_DIR}/{run_id}\"\n",
    "\n",
    "try:\n",
    "    path = Path(run_dir)\n",
    "    path.mkdir(parents=True)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init values\n",
    "acc_epochs = np.zeros(NUM_EPOCHS, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_config():\n",
    "    config_obj =  {\n",
    "        # Loading data config\n",
    "        \"pos_file\": POS_FILE,\n",
    "        \"neg_file\": NEG_FILE,\n",
    "\n",
    "        # Preprocessing data config\n",
    "        \"maxlen\": MAXLEN,\n",
    "        \"padnt\": PADNT,\n",
    "        \"pos_label\": POS_LABEL,\n",
    "        \"neg_label\": NEG_LABEL,\n",
    "        \"onehot_charmap\": onehot_charmap,\n",
    "        \"charmap\": charmap,\n",
    "        \"inv_charmap\": inv_charmap,\n",
    "        \"charmap_len\": charmap_len,\n",
    "\n",
    "        # Model config\n",
    "        \"model.version\": classificator.version(),\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"lr\": LR,\n",
    "        \"hidden_layers\": HIDDEN_LAYERS\n",
    "    }\n",
    "\n",
    "    with open(f\"{run_dir}/config.json\", \"w\") as outfile:\n",
    "        json.dump(config_obj, outfile, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_results():\n",
    "    config_obj =  {\n",
    "        \"acc_epochs\": acc_epochs.tolist(),\n",
    "        \"acc_max\": float(acc_epochs.max())\n",
    "    }\n",
    "    # print(config_obj)\n",
    "\n",
    "    with open(f\"{run_dir}/results.json\", \"w\") as outfile:\n",
    "        json.dump(config_obj, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(acc):\n",
    "    plt.plot(acc, label = 'Accuracy')\n",
    "\n",
    "    plt.grid(which = \"minor\")\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.gcf().set_size_inches(10, 5)\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"{run_dir}/metrics.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RNA Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sequences(seqs):\n",
    "  filtered_seqs = []\n",
    "  allowed = ('A', 'T', 'G', 'C')\n",
    "  for seq in seqs:\n",
    "    seq = seq.upper().replace('U', 'T')\n",
    "    \n",
    "    if not contains_certain_characters(seq, allowed):\n",
    "      continue\n",
    "\n",
    "    filtered_seqs.append(seq.ljust(MAXLEN, PADNT)[:MAXLEN])\n",
    "  return filtered_seqs\n",
    "  \n",
    "posdata = filter_sequences(read_input_csv(POS_FILE))\n",
    "negdata = filter_sequences(read_input_csv(NEG_FILE))\n",
    "data_sequences = posdata + negdata\n",
    "labels = (POS_LABEL,) * len(posdata) + (NEG_LABEL,) * len(negdata)\n",
    "# data_sequences = [ (d, POS_LABEL) for d in posdata ] + [ (d, NEG_LABEL) for d in negdata ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-process sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert RNA sequences to one-hot encoding\n",
    "onehot_charmap = {'N':0, 'A': 1, 'C': 2, 'G': 3, 'T': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_charmap(loaded_):\n",
    "  charmap = {'N':0, 'A':1, 'T':2, 'G':3, 'C':4}\n",
    "  inv_charmap = ['N', 'A', 'T', 'G', 'C']\n",
    "  return charmap, inv_charmap\n",
    "\n",
    "charmap, inv_charmap = calc_charmap(data_sequences)\n",
    "charmap_len = len(charmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_model(data, labels):\n",
    "  tokenized_seqs = [ tokenizer(seq, charmap) for seq in data ]\n",
    "\n",
    "  prepared_data = onehot_tokenized(np.array(tokenized_seqs, dtype=np.float32), onehot)\n",
    "  prepared_labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "  return prepared_data, prepared_labels\n",
    "\n",
    "onehot = generate_onehot_encoder(charmap_len)\n",
    "data_sequences_prepared, labels_prepared = prepare_data_model(data_sequences, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_sequences_prepared, labels_prepared,\n",
    "    test_size=0.2, stratify=labels_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RNADataset(X_train, Y_train)\n",
    "test_dataset = RNADataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = BinaryClassificator( len(onehot_charmap), MAXLEN, HIDDEN_LAYERS ).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True, Device: cuda\n",
      "==> Epoch 10/100 - acc=0.893\n",
      "==> Epoch 20/100 - acc=0.907\n",
      "==> Epoch 30/100 - acc=0.902\n",
      "==> Epoch 40/100 - acc=0.893\n",
      "==> Epoch 50/100 - acc=0.916\n",
      "==> Epoch 60/100 - acc=0.893\n",
      "==> Epoch 70/100 - acc=0.893\n",
      "==> Epoch 80/100 - acc=0.889\n",
      "==> Epoch 90/100 - acc=0.889\n",
      "==> Epoch 100/100 - acc=0.871\n",
      "Last model saved to: ./cnnanalyzer_models/20240715_111145/last.pt (acc:0.871)\n",
      "Best model saved to: ./cnnanalyzer_models/20240715_111145/best.pt (acc:0.916)\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_weights = None\n",
    "\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer_classificator = optim.Adam(classificator.parameters(), lr=LR)\n",
    "\n",
    "print(f\"Using CUDA: {use_cuda}, Device: {device}\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_user = epoch + 1\n",
    "    classificator.train()\n",
    "\n",
    "    for x_real, y_real in trainloader:\n",
    "\n",
    "        # classificator.zero_grad()\n",
    "\n",
    "        x_real = x_real.to(device=device)\n",
    "        y_real = y_real.to(device=device)\n",
    "\n",
    "        # foward pass\n",
    "        y_pred = classificator(x_real)\n",
    "        y_pred = y_pred.reshape(-1)\n",
    "\n",
    "        # loss\n",
    "        loss = loss_fn(y_pred, y_real)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer_classificator.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer_classificator.step()\n",
    "\n",
    "    classificator.eval()\n",
    "    # for x_test, y_test in testloader:\n",
    "    x_test, y_test = next(iter(testloader))\n",
    "    acc = eval_model(classificator, x_test, y_test, device)\n",
    "    acc_epochs[epoch] = acc\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = copy.deepcopy(classificator.state_dict())\n",
    "\n",
    "    if epoch_user % 10 == 0:\n",
    "        print(\"==> Epoch {epoch}/{maxepoch} - acc={acc:.3f}\".format(epoch=epoch_user,maxepoch=NUM_EPOCHS,acc=acc))\n",
    "        plot_metrics(acc_epochs)\n",
    "\n",
    "# save the final model\n",
    "r = save_models(run_dir, classificator, \"last\")\n",
    "print(\"Last model saved to: {path} (acc:{acc:.3f})\".format(path=r,acc=acc_epochs[-1]))\n",
    "\n",
    "classificator.load_state_dict(best_weights)\n",
    "r = save_models(run_dir, classificator, \"best\")\n",
    "print(\"Best model saved to: {path} (acc:{acc:.3f})\".format(path=r,acc=best_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc_epochs': [0.6311111450195312, 0.8488889336585999, 0.8533333539962769, 0.8577777743339539, 0.8666666746139526, 0.8577777743339539, 0.8711111545562744, 0.8755555748939514, 0.8799999952316284, 0.893333375453949, 0.897777795791626, 0.902222216129303, 0.9066666960716248, 0.9155555963516235, 0.9155555963516235, 0.9111111164093018, 0.9066666960716248, 0.897777795791626, 0.9111111164093018, 0.9066666960716248, 0.897777795791626, 0.9111111164093018, 0.897777795791626, 0.9111111164093018, 0.893333375453949, 0.902222216129303, 0.902222216129303, 0.9111111164093018, 0.902222216129303, 0.902222216129303, 0.9111111164093018, 0.9111111164093018, 0.9066666960716248, 0.9066666960716248, 0.897777795791626, 0.897777795791626, 0.902222216129303, 0.902222216129303, 0.893333375453949, 0.893333375453949, 0.9066666960716248, 0.8888888955116272, 0.8888888955116272, 0.9066666960716248, 0.8888888955116272, 0.8888888955116272, 0.9155555963516235, 0.8888888955116272, 0.8844444751739502, 0.9155555963516235, 0.8844444751739502, 0.9111111164093018, 0.8888888955116272, 0.8888888955116272, 0.9155555963516235, 0.8799999952316284, 0.902222216129303, 0.9066666960716248, 0.8888888955116272, 0.893333375453949, 0.902222216129303, 0.893333375453949, 0.897777795791626, 0.8888888955116272, 0.8888888955116272, 0.893333375453949, 0.893333375453949, 0.8844444751739502, 0.8888888955116272, 0.893333375453949, 0.893333375453949, 0.8755555748939514, 0.8888888955116272, 0.8844444751739502, 0.8888888955116272, 0.8799999952316284, 0.8888888955116272, 0.8888888955116272, 0.8755555748939514, 0.8888888955116272, 0.893333375453949, 0.8622222542762756, 0.8799999952316284, 0.8844444751739502, 0.8666666746139526, 0.8844444751739502, 0.8799999952316284, 0.8711111545562744, 0.8799999952316284, 0.8888888955116272, 0.897777795791626, 0.8666666746139526, 0.7688888907432556, 0.8799999952316284, 0.8533333539962769, 0.8177778124809265, 0.8622222542762756, 0.8622222542762756, 0.8711111545562744, 0.8711111545562744], 'acc_max': 0.9155555963516235}\n"
     ]
    }
   ],
   "source": [
    "dump_config()\n",
    "dump_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirgan_gan004",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
