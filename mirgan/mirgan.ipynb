{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import getopt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from mirgan_utils import gpu_test, load_dataset, create_ones, generate_onehot_encoder, \\\n",
    "  to_var, torch_onehot, decode_onehot, seq_data_exploration, save_models\n",
    "from preprocessing_utils import calc_charmap, filter_sequences, tokenizer, detokenizer, seq_maxlenght\n",
    "from architecture import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usage():\n",
    "    # mode = 0 | WGAN\n",
    "    # mode = 1 | FBGAN + CnnAnalyzer\n",
    "\n",
    "    # python mirgan/mirgan.py --mode 0 --input input.txt --outputdir directory\n",
    "    s = \"USAGE: \" \\\n",
    "        + \"python mirgan/mirgan.py \" \\\n",
    "        + \"--mode int \" \\\n",
    "        + \"--input input.txt \" \\\n",
    "        + \"--outputdir directory \"\n",
    "    print(s)\n",
    "    \n",
    "def process_argv(argv):\n",
    "\n",
    "    requireds = [\"mode\", \"input\", \"outputdir\"]\n",
    "    input_args = requireds + ['help']\n",
    "\n",
    "    try:\n",
    "        longopts = [ opt + \"=\" for opt in input_args ]\n",
    "        opts, args = getopt.getopt(argv[1:], \"\", longopts)\n",
    "    except getopt.GetoptError as e:\n",
    "        print(\"Wrong usage!\")\n",
    "        print(e)\n",
    "        usage()\n",
    "        sys.exit(1)\n",
    "\n",
    "    # parse the options\n",
    "    r = {}\n",
    "    for op, value in opts:\n",
    "        op = op.replace('--', '')\n",
    "        if op == 'help':\n",
    "            usage()\n",
    "            sys.exit()\n",
    "        elif op in input_args:\n",
    "            r[op] = value\n",
    "\n",
    "    for required in requireds:\n",
    "        if not required in r:\n",
    "            print(\"Wrong usage!!\")\n",
    "            print(\"Param {} is required\".format(required))\n",
    "            usage()\n",
    "            sys.exit(1)\n",
    "\n",
    "    return r\n",
    "\n",
    "def is_notebook() -> bool:\n",
    "    # https://stackoverflow.com/questions/15411967/how-can-i-check-if-code-is-executed-in-the-ipython-notebook\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook():\n",
    "    mode = \"1\"\n",
    "    input = '../input/example_gan_input.txt'\n",
    "    outputdir = '../tmp/test1'\n",
    "\n",
    "    argv = ['filename.py',\n",
    "            \"--mode\", mode,\n",
    "            \"--input\", input,\n",
    "            \"--outputdir\", outputdir\n",
    "            ]\n",
    "    opts = process_argv(argv)\n",
    "\n",
    "if not is_notebook():\n",
    "    opts = process_argv(sys.argv)\n",
    "\n",
    "print(\"opts=\", opts)\n",
    "\n",
    "mode = int(opts['mode'])\n",
    "if mode < 0 or mode > 1:\n",
    "    print(\"Mode arg should be 0 or 1.\")\n",
    "    usage()\n",
    "    raise\n",
    "\n",
    "file_input = opts['input']\n",
    "output_dir = opts['outputdir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# torch.manual_seed(111)\n",
    "\n",
    "max_side = 11\n",
    "max_length = max_side * max_side\n",
    "\n",
    "batch_size = 32\n",
    "retain_generated_sequences = 200\n",
    "\n",
    "lr = 0.0001\n",
    "num_epochs = 100\n",
    "num_epochs_discriminator = 5\n",
    "num_epochs_generator = 1\n",
    "hidden = 512\n",
    "\n",
    "lamda = 10 #lambda\n",
    "\n",
    "models_dir = f'{output_dir}/models'\n",
    "generated_dir = f'{output_dir}/generated'\n",
    "tmp_dir = f'{output_dir}/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"models_dir={models_dir}\")\n",
    "print(f\"generated_dir={generated_dir}\")\n",
    "print(f\"tmp_dir={tmp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = Path(output_dir)\n",
    "    path.mkdir(parents=True)\n",
    "except FileExistsError:\n",
    "    # print(f\"FileExistsError: {output_dir} already exists\")\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    path = Path(models_dir)\n",
    "    path.mkdir(parents=True)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    path = Path(generated_dir)\n",
    "    path.mkdir(parents=True)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    path = Path(tmp_dir)\n",
    "    path.mkdir(parents=True)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda, device = gpu_test()\n",
    "(use_cuda, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset and return list of sequences\n",
    "loaded_ds = load_dataset(file_input, limit=None)\n",
    "loaded_length = len(loaded_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charmap, inv_charmap = calc_charmap(loaded_ds)\n",
    "filtered_seqs = filter_sequences(loaded_ds, max_length=max_length)\n",
    "charmap_len = len(charmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqs_to_trainset(input_seqs):\n",
    "  tokenized_seqs = [ tokenizer(seq, charmap) for seq in input_seqs ]\n",
    "\n",
    "  train_data_length = len(tokenized_seqs)\n",
    "  train_data = torch.tensor(np.array(tokenized_seqs))\n",
    "\n",
    "  train_labels = torch.zeros(train_data_length)\n",
    "\n",
    "  r = [ (x,y) for (x,y) in zip(train_data, train_labels) ]\n",
    "  return r\n",
    "\n",
    "train_set = seqs_to_trainset(filtered_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator and the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator( charmap_len, max_length, batch_size, hidden ).to(device=device)\n",
    "generator = Generator( charmap_len, max_length, batch_size, hidden ).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam algorithm to train the discriminator and generator models\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = generate_onehot_encoder(charmap_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(real_data, fake_data):\n",
    "  alpha = torch.rand(batch_size, 1, 1)\n",
    "  alpha = alpha.view(-1,1,1)\n",
    "  alpha = alpha.expand_as(real_data)\n",
    "  alpha = alpha.cuda() if use_cuda else alpha\n",
    "  interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "  interpolates = interpolates.cuda() if use_cuda else interpolates\n",
    "  interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "  disc_interpolates = discriminator(interpolates)\n",
    "\n",
    "  gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                grad_outputs=torch.ones(disc_interpolates.size()).cuda() \\\n",
    "                if use_cuda else torch.ones(disc_interpolates.size()),\n",
    "                create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "  gradient_penalty = ((gradients.norm(2, dim=1).norm(2,dim=1) - 1) ** 2).mean() * lamda\n",
    "  return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one, one_neg = create_ones(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_sample(batch_size):\n",
    "  z_input = to_var(torch.randn(batch_size, 100))\n",
    "  fake_samples = generator(z_input).detach()\n",
    "  return fake_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader(dataset):\n",
    "  return torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = 0 | WGAN\n",
    "# mode = 1 | FBGAN + CnnAnalyzer\n",
    "\n",
    "analyzer = None\n",
    "analyzer_threshold = 0\n",
    "\n",
    "if mode == 1:\n",
    "    from analyzer_loader import analyzer, analyzer_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sequences(sequences, save_dir, prefix):\n",
    "  output_file = f'{save_dir}/{prefix}.txt'\n",
    "  with open(output_file, 'w') as fp:\n",
    "    for seq in sequences:\n",
    "      fp.write(\"%s\\n\" % seq)\n",
    "\n",
    "def save_trainset(sequences, save_dir, prefix):\n",
    "  output = []\n",
    "  for seq in sequences:\n",
    "    seq = detokenizer(seq[0], inv_charmap)\n",
    "    output.append( ''.join(seq).rstrip('P') )\n",
    "  save_sequences( output, save_dir, f\"trainset_{prefix}\" )\n",
    "\n",
    "def generated_sample_to_string(generated_sequence):\n",
    "  seq = ''.join(detokenizer(decode_onehot(generated_sequence), inv_charmap))\n",
    "  seq = seq.rstrip('P')\n",
    "\n",
    "  return seq\n",
    "\n",
    "def analyzer_filter2(generated_sequence):\n",
    "  if 'P' in generated_sequence: return None\n",
    "  if len(generated_sequence) < 50: return None\n",
    "  return generated_sequence\n",
    "\n",
    "def analyzer_run(epoch):\n",
    "  if analyzer is None: return []\n",
    "  \n",
    "  generated_samples = generator_sample(batch_size)\n",
    "  generated_samples_np = (generated_samples.data).cpu().numpy()\n",
    "\n",
    "  generated_samples_filtered = []\n",
    "  generated_samples_tosave = []\n",
    "  for n, seq in enumerate(generated_samples_np):\n",
    "    seq1 = generated_sample_to_string(seq)\n",
    "    generated_samples_tosave.append( seq1 )\n",
    "\n",
    "    seq2 = analyzer_filter2(seq1)\n",
    "\n",
    "    if not seq2 is None:\n",
    "      generated_samples_filtered.append( { 'id':'seq%04d' % n, 'seq': seq2 } )\n",
    "\n",
    "  save_sequences(generated_samples_tosave, generated_dir, \"generated_samples_%04d\" % epoch)\n",
    "\n",
    "  if not generated_samples_filtered: return []\n",
    "\n",
    "  # run analyzer\n",
    "  analyzer.setInput(generated_samples_filtered)\n",
    "  analyzer.prepare()\n",
    "  analyzer.run()\n",
    "  analyzer_results = analyzer.getScores()\n",
    "  # analyzer.clear()\n",
    "\n",
    "  # filter analyzer results\n",
    "  positive_sequences = []\n",
    "  scored_sequences = []\n",
    "  for generated_sequence in generated_samples_filtered:\n",
    "\n",
    "    scored_sequences.append( {\"id\": generated_sequence['id'], \\\n",
    "      \"score\": round(analyzer_results[ generated_sequence['id'] ]['score'], 3), \\\n",
    "      \"seq\": generated_sequence[\"seq\"]} )\n",
    "\n",
    "    if analyzer_results[ generated_sequence['id'] ]['score'] >= analyzer_threshold:\n",
    "      positive_sequences.append( tuple( seq_maxlenght(generated_sequence['seq'], max_length) ) )\n",
    "  \n",
    "  if scored_sequences:\n",
    "    with open(f'{generated_dir}/scores_{epoch}.csv', 'w', newline='') as output_file:\n",
    "      dict_writer = csv.DictWriter(output_file, scored_sequences[0].keys())\n",
    "      dict_writer.writeheader()\n",
    "      dict_writer.writerows(scored_sequences)\n",
    "\n",
    "  return positive_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_samples):\n",
    "  real_data = torch_onehot(real_samples, onehot).to(device=device)\n",
    "  \n",
    "  discriminator.zero_grad()\n",
    "  d_real_pred = discriminator(real_data)\n",
    "  d_real_err = torch.mean(d_real_pred) #want to push d_real as high as possible\n",
    "  d_real_err.backward(one_neg)\n",
    "\n",
    "  # d_fake_data = generator_sample(batch_size)\n",
    "  z_input = to_var(torch.randn(batch_size, 100))\n",
    "  d_fake_data = generator(z_input).detach()\n",
    "  \n",
    "  d_fake_pred = discriminator(d_fake_data)\n",
    "  d_fake_err = torch.mean(d_fake_pred) #want to push d_fake as low as possible\n",
    "  d_fake_err.backward(one)\n",
    "\n",
    "  gradient_penalty = calc_gradient_penalty(real_data.data, d_fake_data.data)\n",
    "  gradient_penalty.backward()\n",
    "\n",
    "  d_err = d_fake_err - d_real_err + gradient_penalty\n",
    "  optimizer_discriminator.step()\n",
    "\n",
    "  return d_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "  generator.zero_grad()\n",
    "\n",
    "  # g_fake_data = generator_sample(batch_size)\n",
    "  z_input = to_var(torch.randn(batch_size, 100))\n",
    "  g_fake_data = generator(z_input)\n",
    "  \n",
    "  dg_fake_pred = discriminator(g_fake_data)\n",
    "  g_err = -torch.mean(dg_fake_pred)\n",
    "  g_err.backward()\n",
    "  optimizer_generator.step()\n",
    "\n",
    "  return g_err, g_fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss(loss_discriminator, loss_generator, analyzer_positives, mse_list):\n",
    "    plt.plot(loss_discriminator, label = 'D_loss')\n",
    "    plt.plot(loss_generator, label = 'G_loss')\n",
    "    plt.plot(analyzer_positives, label = 'Analyzer Positives')\n",
    "    plt.plot(mse_list, label = 'MSE')\n",
    "\n",
    "    loss_sum = np.abs(loss_discriminator) + np.absolute(loss_generator)\n",
    "    plt.plot(loss_sum, label = 'Sum')\n",
    "\n",
    "    plt.grid(which = \"minor\")\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.gcf().set_size_inches(10, 5)\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"{output_dir}/chart.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    with open(f\"{output_dir}/chart.json\", 'w') as fp:\n",
    "        d = {\n",
    "            \"loss_discriminator\": loss_discriminator.tolist(),\n",
    "            \"loss_generator\": loss_generator.tolist(),\n",
    "            \"analyzer_positives\": analyzer_positives.tolist(),\n",
    "            \"mse_list\": mse_list.tolist(),\n",
    "        }\n",
    "        json.dump(d, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse_seqs(A, B):\n",
    "    mse_sum = 0\n",
    "    for k, a in enumerate(A):\n",
    "        mse_min = min([ calc_mse_sequence(a, b) for b in B ])\n",
    "        mse_sum += mse_min\n",
    "    return mse_sum\n",
    "\n",
    "def calc_mse_sequence(seq_a, seq_b):\n",
    "    mse_sum = 0\n",
    "    for nt_a, nt_b in zip(seq_a, seq_b):\n",
    "        if np.argmax(nt_a) == np.argmax(nt_b):\n",
    "            continue\n",
    "        mse_sum += calc_mse_nt(nt_a, nt_b)\n",
    "    return mse_sum / seq_a.shape[0]\n",
    "\n",
    "def calc_mse_nt(nt_a, nt_b):\n",
    "    return np.square(np.subtract(nt_a, nt_b)).mean()\n",
    "\n",
    "mse_real_data = np.array( [train_set_item[0] for train_set_item in train_set] )\n",
    "mse_real_data = torch_onehot(mse_real_data, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_discriminator_list = np.zeros(num_epochs)\n",
    "loss_generator_list = np.zeros(num_epochs)\n",
    "analyzer_positives_list = np.zeros(num_epochs)\n",
    "mse_list = np.zeros(num_epochs)\n",
    "\n",
    "def train_gan():\n",
    "  print(\"device=\", device)\n",
    "\n",
    "  generated_positives = []\n",
    "\n",
    "  for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"==> Epoch: {epoch}\")\n",
    "\n",
    "    # train_set.extend( seqs_to_trainset(positive_sequences) )\n",
    "    analyzer_positives = analyzer_run(epoch)\n",
    "    analyzer_positives_len = len(analyzer_positives) if analyzer_positives else 0\n",
    "    analyzer_positives_list[epoch-1] = analyzer_positives_len\n",
    "    if analyzer_positives:\n",
    "      generated_positives.extend(analyzer_positives)\n",
    "      generated_positives = generated_positives[-retain_generated_sequences:]\n",
    "      print(f\"Analyzer: added {analyzer_positives_len} seqs\")\n",
    "    \n",
    "    train_set_positives = seqs_to_trainset(generated_positives)\n",
    "    train_loader = get_train_loader(train_set + train_set_positives)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "      save_trainset(train_set_positives, generated_dir, \"epoch_%04d\" % epoch)\n",
    "\n",
    "    d_err, g_err, g_fake_data = None, None, []\n",
    "\n",
    "    for n, (real_samples, real_labels) in enumerate(train_loader):\n",
    "      \n",
    "      # Train Discriminator\n",
    "      for i in range(num_epochs_discriminator):\n",
    "        d_err = train_discriminator(real_samples)\n",
    "\n",
    "      # Train Generator\n",
    "      for i in range(num_epochs_generator):\n",
    "        g_err, g_fake_data = train_generator()\n",
    "\n",
    "    # Show loss\n",
    "    if not d_err is None:\n",
    "      loss_discriminator = (d_err.data).cpu().numpy()\n",
    "      loss_generator = (g_err.data).cpu().numpy()\n",
    "\n",
    "      loss_discriminator_list[epoch-1] = loss_discriminator\n",
    "      loss_generator_list[epoch-1] = loss_generator\n",
    "\n",
    "      g_fake_data = generator_sample(32).cpu().numpy()\n",
    "      mse = calc_mse_seqs(g_fake_data, mse_real_data)\n",
    "      mse_list[epoch-1] = mse\n",
    "      print(f\"MSE: {mse}\")\n",
    "\n",
    "      print(f\"Loss D.: {loss_discriminator} Loss G.: {loss_generator}\")\n",
    "      save_loss(loss_discriminator_list, loss_generator_list, analyzer_positives_list, mse_list)\n",
    "\n",
    "      # save_models(models_dir, discriminator, generator, str(epoch))\n",
    "\n",
    "train_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(models_dir, discriminator, generator, \"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6070bf36e016a2c44bee296e1e25268245dd754c68fdedbd78ba329a2bfda587"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
